---
title: "Machine learning classification of siRNA depletion data"
output: html_notebook
---

This notebook contains the code for training the ML classifier for the siRNA depletion data.

It then contains the code to save the results of manual co-polarization scoring.

NOTE: This notebook contains a preliminary assessment of accuracy which was used during optimization of the ML training to choose classification models. It uses cells which included those used during iterative training (excluding the cells for the training set for each respective round). This may bias the results because the test set is not fully independent of iterative training. 
Accuracy for the paper was reported on a separate sample of cells scored later which excluded any cells used in iterative training. This analysis is shown in the Sensitivity-Specificity-Precision-ImportantFeatures.Rmd notebook.

Load packages:
```{r}
options(java.parameters = "-Xmx8g")
library(readxl)
library(tidyverse)
library(caret)
library(gridExtra)
library(corrplot)
options(rgl.useNULL=TRUE)
library(rgl)
library(Rdimtools)
library(gbm)
library(extraTrees)
library(caretEnsemble)
library(ggbeeswarm)

```
Functions
```{r}
# This function accepts Matlab output for 2- or 3-channel experiments, and combines them into one data.frame, appending the variable names of the channel specific measurements with the channel name provided in the input (e.g., the name of the stained protein). For a 3-channel experiment Matlab exports 4 files. The _Cell file contains colocalization metrics and measurements shared by all channels (i.e., Area, Max Feret Diameter, etc.). The other files (_chName) contain channel specific measurements. Provide the full path for the matlab files in the function input.
importMatlabMulti <- function(matlabCell, matlabChannel1, matlabChannel2, matlabChannel3, annotation, ch1Name, ch2Name, ch3Name){
  cellMeasRaw <- read.csv(matlabCell)
  cellMeas <- cellMeasRaw %>%
    filter(!cell == "")
  cellMeas <- unique(cellMeas)
  
  ch1 <- unique(cbind(cellMeasRaw %>% dplyr::select(Area, cell), read.csv(matlabChannel1))) %>%
    filter(!is.na(intensityWrampHalves)) %>%
    dplyr::rename(meanIntensityNotWramp = meanNotWramp,
           medianIntensityNotWramp = medianNotWramp,
           sumIntensityNotWramp = sumNotWramp,
           meanIntensityNotBright = meanNotBright,
           sumIntensityNotBright = sumNotBright,
           medianIntensityNotBright = medianNotBright) %>%
    dplyr::mutate(meanWrampOverNot = meanIntensityWramp/meanIntensityNotWramp,
           meanWrampOverNotBright = meanIntensityWramp/meanIntensityNotBright,
           meanSecondOverNotBright = meanIntensitySecond/meanIntensityNotBright,
           sumWrampOverNot = sumIntensityWramp/sumIntensityNotWramp,
           sumWrampOverNotBright = sumIntensityWramp/sumIntensityNotBright,
           sumSecondOverNotBright = sumIntensitySecond/sumIntensityNotBright,
           medianWrampOverNot = medianIntensityWramp/medianIntensityNotWramp,
           medianWrampOverNotBright = medianIntensityWramp/medianIntensityNotBright,
           medianSecondOverNotBright = medianIntensitySecond/medianIntensityNotBright,
           sumOverMedianIntensityWramp = sumIntensityWramp/medianIntensityWramp,
           relAreaWrampCell = areaWramp/Area,
           relAreaWrampBright = areaWramp/areaBrightObj,
           massDisplacement = ifelse(massDisplacement < 1, 1, massDisplacement)) %>%
    dplyr::select(-Area) %>%
    rename_with(~str_c(.,paste("_", ch1Name, sep = "")), .cols = -contains("cell", ignore.case = F))
  ch2 <- unique(cbind(read.csv(matlabChannel2), cellMeasRaw %>% dplyr::select(Area, cell))) %>%
    filter(cell %in% ch1$cell) %>%
    dplyr::rename(meanIntensityNotWramp = meanNotWramp,
           medianIntensityNotWramp = medianNotWramp,
           sumIntensityNotWramp = sumNotWramp,
           meanIntensityNotBright = meanNotBright,
           sumIntensityNotBright = sumNotBright,
           medianIntensityNotBright = medianNotBright) %>%
    dplyr::mutate(meanWrampOverNot = meanIntensityWramp/meanIntensityNotWramp,
           meanWrampOverNotBright = meanIntensityWramp/meanIntensityNotBright,
           meanSecondOverNotBright = meanIntensitySecond/meanIntensityNotBright,
           sumWrampOverNot = sumIntensityWramp/sumIntensityNotWramp,
           sumWrampOverNotBright = sumIntensityWramp/sumIntensityNotBright,
           sumSecondOverNotBright = sumIntensitySecond/sumIntensityNotBright,
           medianWrampOverNot = medianIntensityWramp/medianIntensityNotWramp,
           medianWrampOverNotBright = medianIntensityWramp/medianIntensityNotBright,
           medianSecondOverNotBright = medianIntensitySecond/medianIntensityNotBright,
           sumOverMedianIntensityWramp = sumIntensityWramp/medianIntensityWramp,
           relAreaWrampCell = areaWramp/Area,
           relAreaWrampBright = areaWramp/areaBrightObj,
           massDisplacement = ifelse(massDisplacement < 1, 1, massDisplacement)) %>%
        dplyr::select(-Area) %>%
    rename_with(~str_c(.,paste("_", ch2Name, sep = "")), .cols = -contains("cell", ignore.case = F))
  if(matlabChannel3 != "empty"){
    ch3 <- unique(cbind(cellMeasRaw %>% dplyr::select(Area, cell), read.csv(matlabChannel3))) %>%
      filter(cell %in% ch1$cell) %>%
      dplyr::rename(meanIntensityNotWramp = meanNotWramp,
             medianIntensityNotWramp = medianNotWramp,
             sumIntensityNotWramp = sumNotWramp,
             meanIntensityNotBright = meanNotBright,
             sumIntensityNotBright = sumNotBright,
             medianIntensityNotBright = medianNotBright) %>%
      dplyr::mutate(meanWrampOverNot = meanIntensityWramp/meanIntensityNotWramp,
             meanWrampOverNotBright = meanIntensityWramp/meanIntensityNotBright,
             meanSecondOverNotBright = meanIntensitySecond/meanIntensityNotBright,
             sumWrampOverNot = sumIntensityWramp/sumIntensityNotWramp,
             sumWrampOverNotBright = sumIntensityWramp/sumIntensityNotBright,
             sumSecondOverNotBright = sumIntensitySecond/sumIntensityNotBright,
             medianWrampOverNot = medianIntensityWramp/medianIntensityNotWramp,
             medianWrampOverNotBright = medianIntensityWramp/medianIntensityNotBright,
             medianSecondOverNotBright = medianIntensitySecond/medianIntensityNotBright,
             sumOverMedianIntensityWramp = sumIntensityWramp/medianIntensityWramp,
             relAreaWrampCell = areaWramp/Area,
             relAreaWrampBright = areaWramp/areaBrightObj,
             massDisplacement = ifelse(massDisplacement < 1, 1, massDisplacement)) %>%
      dplyr::select(-Area) %>%
      rename_with(~str_c(.,paste("_", ch3Name, sep = "")), .cols = -contains("cell", ignore.case = F))
  }
  
  if(matlabChannel3 != "empty"){
    matlab <- merge(cellMeas, merge(ch1, merge(ch2, ch3, by = "cell"), by = "cell"), by = "cell")
  }else{
    matlab <- merge(cellMeas, merge(ch1, ch2, by = "cell"), by = "cell")
  }
  matlab <- matlab %>%
    separate(cell, into = c("Image", "ObjectNumber"), sep = "Cell_", convert = TRUE) %>%
    dplyr::select(-Image) %>%
    dplyr::rename(Image = image) %>%
    #filter(!is.na(ObjectNumber)) %>%
    unite(Object, c("Image","ObjectNumber"), remove = FALSE) %>%
    dplyr::select(-ObjectNumber) %>%
    arrange(Object)
    
  
  matlabAnnotated <- merge(annotation, matlab, by = "Image")
}

# This function reads cell-level results from CellProfiler and adds annotation from the image file
readCp <- function(cpImgPath, cpCellPath){
  cpImg <-read.csv(cpImgPath)
  
  if(any(str_detect(colnames(cpImg), "Image_FileName_ImgMcam"))){
    cpCell <- merge(read.csv(cpCellPath), dplyr::select(cpImg, ImageNumber, Image_FileName_ImgMcam), by = "ImageNumber") %>%
      unite(Object, c(Image_FileName_ImgMcam, ObjectNumber), remove = F) %>%
      arrange(Object)
  }else{
    cpCell <- merge(read.csv(cpCellPath), dplyr::select(cpImg, ImageNumber, Image_FileName_ImgMain), by = "ImageNumber") %>%
      unite(Object, c(Image_FileName_ImgMain, ObjectNumber), remove = F) %>%
      arrange(Object)
  }
}

# This function combines features measured in matlab and CellProfiler, removes redundant features, calculates CV for Intensity and IntensityEdge from CellProfiler measurements, converts Haralick features into rotation-invariant form (not angularly dependent) by taking the mean and range, and removes small round cells based on area and max Feret diameter. CellProfiler subscript (cpSubscript) and matlab channel names (chName) indicating the different channels need to match the subscripts in the input dataframes.
combineMetrics <- function(matlab, cpCell, cpSubscript1, cpSubscript2, cpSubscript3, chName1, chName2, chName3){
  metrics <- merge(matlab, cpCell, by = "Object") %>%
    dplyr::select(-AreaShape_Orientation, 
           -contains("Intensity_MedianIntensity_BgSubtracted"), 
           -contains("Intensity_IntegratedIntensity"),
           -contains("Intensity_MassDisplacement"),
           -Number_Object_Number,
           -AreaShape_MajorAxisLength, 
           -AreaShape_MinorAxisLength, 
           -AreaShape_MaxFeretDiameter,
           -AreaShape_MinFeretDiameter,
           -AreaShape_Eccentricity,
           -AreaShape_Area) %>% # Remove identical metrics from matlab and CellProfiler
    dplyr::select(-OriginalId, -contains("Image_FileName_"),
           -contains("MaxFeretCoordinates"), -contains("MinFeretCoordinates"), 
           -contains("Orientation"), -contains("MaxFeretAngle"), -contains("MinFeretAngle"), 
           -contains("wrampAngle"), -contains("secondAngle"), -contains("majAngle"), 
           -contains("Center_X"), -contains("Center_Y"), -contains("Center_Z"), -contains("Location_"), 
           -contains("BoundingBoxM"), -contains("EulerNumber")) # Remove coordinate-based metrics and nonnumeric info. 
  
  texturize <- function(cpSubscript, chName){
    metricsTexture <- metrics %>% 
      dplyr::select(Object, contains("Texture"), contains("Intensity_StdIntensityEdge"), contains("Intensity_MeanIntensity"), contains("Intensity_StdIntensity")) %>%
      dplyr::select(Object, contains(cpSubscript)) %>%
      rename_with(~gsub(cpSubscript, '', .x), .cols = everything()) %>%
      rowwise() %>%
      dplyr::mutate(Texture_AngularSecondMoment_2_Mean = mean(c(Texture_AngularSecondMoment_2_00_256, Texture_AngularSecondMoment_2_01_256, Texture_AngularSecondMoment_2_02_256, Texture_AngularSecondMoment_2_03_256)),
           Texture_AngularSecondMoment_8_Mean = mean(c(Texture_AngularSecondMoment_8_00_256, Texture_AngularSecondMoment_8_01_256, Texture_AngularSecondMoment_8_02_256, Texture_AngularSecondMoment_8_03_256)),
           Texture_Contrast_2_Mean = mean(c(Texture_Contrast_2_00_256, Texture_Contrast_2_01_256, Texture_Contrast_2_02_256, Texture_Contrast_2_03_256)),
           Texture_Contrast_8_Mean = mean(c(Texture_Contrast_8_00_256, Texture_Contrast_8_01_256, Texture_Contrast_8_02_256, Texture_Contrast_8_03_256)),
           Texture_Correlation_2_Mean = mean(c(Texture_Correlation_2_00_256, Texture_Correlation_2_01_256, Texture_Correlation_2_02_256, Texture_Correlation_2_03_256)),
           Texture_Correlation_8_Mean = mean(c(Texture_Correlation_8_00_256, Texture_Correlation_8_01_256, Texture_Correlation_8_02_256, Texture_Correlation_8_03_256)),
           Texture_DifferenceEntropy_2_Mean = mean(c(Texture_DifferenceEntropy_2_00_256, Texture_DifferenceEntropy_2_01_256, Texture_DifferenceEntropy_2_02_256, Texture_DifferenceEntropy_2_03_256)),
           Texture_DifferenceEntropy_8_Mean = mean(c(Texture_DifferenceEntropy_8_00_256, Texture_DifferenceEntropy_8_01_256, Texture_DifferenceEntropy_8_02_256, Texture_DifferenceEntropy_8_03_256)),
           Texture_DifferenceVariance_2_Mean = mean(c(Texture_DifferenceVariance_2_00_256, Texture_DifferenceVariance_2_01_256, Texture_DifferenceVariance_2_02_256, Texture_DifferenceVariance_2_03_256)),
           Texture_DifferenceVariance_8_Mean = mean(c(Texture_DifferenceVariance_8_00_256, Texture_DifferenceVariance_8_01_256, Texture_DifferenceVariance_8_02_256, Texture_DifferenceVariance_8_03_256)),
           Texture_Entropy_2_Mean = mean(c(Texture_Entropy_2_00_256, Texture_Entropy_2_01_256, Texture_Entropy_2_02_256, Texture_Entropy_2_03_256)),
           Texture_Entropy_8_Mean = mean(c(Texture_Entropy_8_00_256, Texture_Entropy_8_01_256, Texture_Entropy_8_02_256, Texture_Entropy_8_03_256)),
           Texture_InfoMeas1_2_Mean = mean(c(Texture_InfoMeas1_2_00_256, Texture_InfoMeas1_2_01_256, Texture_InfoMeas1_2_02_256, Texture_InfoMeas1_2_03_256)),
           Texture_InfoMeas1_8_Mean = mean(c(Texture_InfoMeas1_8_00_256, Texture_InfoMeas1_8_01_256, Texture_InfoMeas1_8_02_256, Texture_InfoMeas1_8_03_256)),
           Texture_InfoMeas2_2_Mean = mean(c(Texture_InfoMeas2_2_00_256, Texture_InfoMeas2_2_01_256, Texture_InfoMeas2_2_02_256, Texture_InfoMeas2_2_03_256)),
           Texture_InfoMeas2_8_Mean = mean(c(Texture_InfoMeas2_8_00_256, Texture_InfoMeas2_8_01_256, Texture_InfoMeas2_8_02_256, Texture_InfoMeas2_8_03_256)),
           Texture_InverseDifferenceMoment_2_Mean = mean(c(Texture_InverseDifferenceMoment_2_00_256, Texture_InverseDifferenceMoment_2_01_256, Texture_InverseDifferenceMoment_2_02_256, Texture_InverseDifferenceMoment_2_03_256)),
           Texture_InverseDifferenceMoment_8_Mean = mean(c(Texture_InverseDifferenceMoment_8_00_256, Texture_InverseDifferenceMoment_8_01_256, Texture_InverseDifferenceMoment_8_02_256, Texture_InverseDifferenceMoment_8_03_256)),
           Texture_SumAverage_2_Mean = mean(c(Texture_SumAverage_2_00_256, Texture_SumAverage_2_01_256, Texture_SumAverage_2_02_256, Texture_SumAverage_2_03_256)),
           Texture_SumAverage_8_Mean = mean(c(Texture_SumAverage_8_00_256, Texture_SumAverage_8_01_256, Texture_SumAverage_8_02_256, Texture_SumAverage_8_03_256)),
           Texture_SumEntropy_2_Mean = mean(c(Texture_SumEntropy_2_00_256, Texture_SumEntropy_2_01_256, Texture_SumEntropy_2_02_256, Texture_SumEntropy_2_03_256)),
           Texture_SumEntropy_8_Mean = mean(c(Texture_SumEntropy_8_00_256, Texture_SumEntropy_8_01_256, Texture_SumEntropy_8_02_256, Texture_SumEntropy_8_03_256)),
           Texture_SumVariance_2_Mean = mean(c(Texture_SumVariance_2_00_256, Texture_SumVariance_2_01_256, Texture_SumVariance_2_02_256, Texture_SumVariance_2_03_256)),
           Texture_SumVariance_8_Mean = mean(c(Texture_SumVariance_8_00_256, Texture_SumVariance_8_01_256, Texture_SumVariance_8_02_256, Texture_SumVariance_8_03_256)),
           Texture_Variance_2_Mean = mean(c(Texture_Variance_2_00_256, Texture_Variance_2_01_256, Texture_Variance_2_02_256, Texture_Variance_2_03_256)),
           Texture_Variance_8_Mean = mean(c(Texture_Variance_8_00_256, Texture_Variance_8_01_256, Texture_Variance_8_02_256, Texture_Variance_8_03_256)),
           Texture_AngularSecondMoment_2_Range = diff(range(c(Texture_AngularSecondMoment_2_00_256, Texture_AngularSecondMoment_2_01_256, Texture_AngularSecondMoment_2_02_256, Texture_AngularSecondMoment_2_03_256))),
           Texture_AngularSecondMoment_8_Range = diff(range(c(Texture_AngularSecondMoment_8_00_256, Texture_AngularSecondMoment_8_01_256, Texture_AngularSecondMoment_8_02_256, Texture_AngularSecondMoment_8_03_256))),
           Texture_Contrast_2_Range = diff(range(c(Texture_Contrast_2_00_256, Texture_Contrast_2_01_256, Texture_Contrast_2_02_256, Texture_Contrast_2_03_256))),
           Texture_Contrast_8_Range = diff(range(c(Texture_Contrast_8_00_256, Texture_Contrast_8_01_256, Texture_Contrast_8_02_256, Texture_Contrast_8_03_256))),
           Texture_Correlation_2_Range = diff(range(c(Texture_Correlation_2_00_256, Texture_Correlation_2_01_256, Texture_Correlation_2_02_256, Texture_Correlation_2_03_256))),
           Texture_Correlation_8_Range = diff(range(c(Texture_Correlation_8_00_256, Texture_Correlation_8_01_256, Texture_Correlation_8_02_256, Texture_Correlation_8_03_256))),
           Texture_DifferenceEntropy_2_Range = diff(range(c(Texture_DifferenceEntropy_2_00_256, Texture_DifferenceEntropy_2_01_256, Texture_DifferenceEntropy_2_02_256, Texture_DifferenceEntropy_2_03_256))),
           Texture_DifferenceEntropy_8_Range = diff(range(c(Texture_DifferenceEntropy_8_00_256, Texture_DifferenceEntropy_8_01_256, Texture_DifferenceEntropy_8_02_256, Texture_DifferenceEntropy_8_03_256))),
           Texture_DifferenceVariance_2_Range = diff(range(c(Texture_DifferenceVariance_2_00_256, Texture_DifferenceVariance_2_01_256, Texture_DifferenceVariance_2_02_256, Texture_DifferenceVariance_2_03_256))),
           Texture_DifferenceVariance_8_Range = diff(range(c(Texture_DifferenceVariance_8_00_256, Texture_DifferenceVariance_8_01_256, Texture_DifferenceVariance_8_02_256, Texture_DifferenceVariance_8_03_256))),
           Texture_Entropy_2_Range = diff(range(c(Texture_Entropy_2_00_256, Texture_Entropy_2_01_256, Texture_Entropy_2_02_256, Texture_Entropy_2_03_256))),
           Texture_Entropy_8_Range = diff(range(c(Texture_Entropy_8_00_256, Texture_Entropy_8_01_256, Texture_Entropy_8_02_256, Texture_Entropy_8_03_256))),
           Texture_InfoMeas1_2_Range = diff(range(c(Texture_InfoMeas1_2_00_256, Texture_InfoMeas1_2_01_256, Texture_InfoMeas1_2_02_256, Texture_InfoMeas1_2_03_256))),
           Texture_InfoMeas1_8_Range = diff(range(c(Texture_InfoMeas1_8_00_256, Texture_InfoMeas1_8_01_256, Texture_InfoMeas1_8_02_256, Texture_InfoMeas1_8_03_256))),
           Texture_InfoMeas2_2_Range = diff(range(c(Texture_InfoMeas2_2_00_256, Texture_InfoMeas2_2_01_256, Texture_InfoMeas2_2_02_256, Texture_InfoMeas2_2_03_256))),
           Texture_InfoMeas2_8_Range = diff(range(c(Texture_InfoMeas2_8_00_256, Texture_InfoMeas2_8_01_256, Texture_InfoMeas2_8_02_256, Texture_InfoMeas2_8_03_256))),
           Texture_InverseDifferenceMoment_2_Range = diff(range(c(Texture_InverseDifferenceMoment_2_00_256, Texture_InverseDifferenceMoment_2_01_256, Texture_InverseDifferenceMoment_2_02_256, Texture_InverseDifferenceMoment_2_03_256))),
           Texture_InverseDifferenceMoment_8_Range = diff(range(c(Texture_InverseDifferenceMoment_8_00_256, Texture_InverseDifferenceMoment_8_01_256, Texture_InverseDifferenceMoment_8_02_256, Texture_InverseDifferenceMoment_8_03_256))),
           Texture_SumAverage_2_Range = diff(range(c(Texture_SumAverage_2_00_256, Texture_SumAverage_2_01_256, Texture_SumAverage_2_02_256, Texture_SumAverage_2_03_256))),
           Texture_SumAverage_8_Range = diff(range(c(Texture_SumAverage_8_00_256, Texture_SumAverage_8_01_256, Texture_SumAverage_8_02_256, Texture_SumAverage_8_03_256))),
           Texture_SumEntropy_2_Range = diff(range(c(Texture_SumEntropy_2_00_256, Texture_SumEntropy_2_01_256, Texture_SumEntropy_2_02_256, Texture_SumEntropy_2_03_256))),
           Texture_SumEntropy_8_Range = diff(range(c(Texture_SumEntropy_8_00_256, Texture_SumEntropy_8_01_256, Texture_SumEntropy_8_02_256, Texture_SumEntropy_8_03_256))),
           Texture_SumVariance_2_Range = diff(range(c(Texture_SumVariance_2_00_256, Texture_SumVariance_2_01_256, Texture_SumVariance_2_02_256, Texture_SumVariance_2_03_256))),
           Texture_SumVariance_8_Range = diff(range(c(Texture_SumVariance_8_00_256, Texture_SumVariance_8_01_256, Texture_SumVariance_8_02_256, Texture_SumVariance_8_03_256))),
           Texture_Variance_2_Range = diff(range(c(Texture_Variance_2_00_256, Texture_Variance_2_01_256, Texture_Variance_2_02_256, Texture_Variance_2_03_256))),
           Texture_Variance_8_Range = diff(range(c(Texture_Variance_8_00_256, Texture_Variance_8_01_256, Texture_Variance_8_02_256, Texture_Variance_8_03_256)))) 
    metricsTexture <- metricsTexture %>%
      ungroup() %>%
      dplyr::mutate(CV_IntensityEdge = Intensity_StdIntensityEdge/Intensity_MeanIntensityEdge,
           CV_IntensityCell = Intensity_StdIntensity/Intensity_MeanIntensity) %>%
      dplyr::select(-Intensity_MeanIntensity, -Intensity_StdIntensity, -Intensity_StdIntensityEdge, -Intensity_MeanIntensityEdge) %>%
      rename_with(~str_c(., paste("_", chName, sep = "")), .cols = everything()) %>%
      dplyr::select(-contains("_256"))
  }
  metricsTexture1 <- texturize(cpSubscript1, chName1)
  metricsTexture2 <- texturize(cpSubscript2, chName2)
  if(chName3 != "empty"){metricsTexture3 <- texturize(cpSubscript3, chName3)}
  
  metrics2 <- merge(metrics %>% dplyr::select(-contains("Texture")), metricsTexture1, by.x = "Object", by.y = paste("Object_", chName1, sep = ""))
  metrics3 <- merge(metrics2, metricsTexture2, by.x = "Object", by.y = paste("Object_", chName2, sep = ""))
  if(chName3 != "empty"){
    metrics4 <- merge(metrics3, metricsTexture3, by.x = "Object", by.y = paste("Object_", chName3, sep = ""))
    metricsAll <- metrics4
  }else{
    metricsAll <- metrics3
  }
  
  metricsAll <- metricsAll %>%
      dplyr::select(-contains("Intensity_MeanIntensity_"))
  
  tooSmall <- c(metricsAll %>% filter(Area < 17000 | MaxFeretDiameter < 350) %>% dplyr::select(Object), metrics2 %>% filter(MaxFeretDiameter < 400, Area < 34000) %>% dplyr::select(Object))
  metricsClean <- metricsAll %>%
   filter(!Object %in% tooSmall[[1]], !Object %in% tooSmall[[2]])
}

# Function to rename normAreaFeatures to be specific to a certain channel's variable names:
normAreaFeaturesChannel <- function(normAreaFeatures, chName){
  chInvariantFeatures <- c("Area", "MajorAxisLength", "MinorAxisLength",  "Eccentricity", "MaxFeretDiameter", "MinFeretDiameter", "AreaShape_BoundingBoxArea", "AreaShape_ConvexArea", "AreaShape_EquivalentDiameter", "AreaShape_MaximumRadius", "AreaShape_MeanRadius", "AreaShape_MedianRadius", "AreaShape_Perimeter")

  normAreaChFeatures <- setdiff(normAreaFeatures, chInvariantFeatures) %>%
    str_c(., paste("_", chName, sep = ""))
  features <- c(chInvariantFeatures, normAreaChFeatures)
}

# Function to calculate the median of each area feature across the control condition of cells in the training experiment
controlMedianAreas <- function(metricsClean, normAreaFeatures, manual){
  medianAreas <- metricsClean %>%
    filter(Object %in% manual$Object) %>% # Remove incorrectly segmented (not a single cell) objects
    dplyr::select(all_of(normAreaFeatures), "Normalization") %>%
    filter(Normalization == "Control") %>%
    group_by(Normalization) %>%
    summarize_all(median, na.rm = T) %>%
    ungroup() %>%
    dplyr::select(-Normalization)
} 

# This function scales area-based features by dividing by the median value of cells in the training experiment (control-condition only). It also normalizes intensity values (to account for variability between conditions and experiments collected on different days) by providing values in relative terms (dividing measurements by the mean or integrated intensity of the cell). It is intended for use on V1 features. Features that are already expressed as a proportion or a [0 1] scale are not changed (e.g., profile measurement, relative area, wrampHalves, brightPix, etc.).
scaleAreaIntensity <- function(metrics, normAreaFeatures, controlMedian, colocFeatures, chName, cpSubscript){
  areaMetrics <- dplyr::select(metrics, all_of(normAreaFeatures))
  scaleArea <- as.data.frame(mapply('/', areaMetrics, controlMedian)) #%>%
    #dplyr::mutate_all(log)
  
  annotFeatures <- c("Object", "Image", "Experiment", "Replicate", "Coverslip", "Condition", "mainCondition", "mainReplicate", "experimentGroup", "Normalization")
  normNonArea <- metrics %>%
    dplyr::select(-all_of(colocFeatures)) %>%
    dplyr::select(-all_of(normAreaFeatures)) %>%
    dplyr::select(any_of(annotFeatures), contains(paste("_", chName, sep = "")), contains(cpSubscript)) %>%
    rename_with(~gsub(cpSubscript, '', .x), .cols = contains(cpSubscript)) %>%
    rename_with(~gsub(paste("_", chName, sep = ""), '', .x), .cols = contains(paste("_", chName, sep = ""))) %>%
    dplyr::select(-largeObj, -brightMeanObj, -brightSumObj) %>%
    dplyr::mutate(angleWramp2Major = angleWramp2Major/90,
           angleSecond2Major = angleSecond2Major/90,
           angleWramp2Second = angleWramp2Second/180,
           intensityWrampHalves = log(intensityWrampHalves),
           intensityMajorHalves = log(intensityMajorHalves),
           intensitySecondHalves = log(intensitySecondHalves),
           medianObjectMeanIntensity = medianObjectMeanIntensity/meanIntensityCell, # Fixed
           medianObjectSumIntensity = medianObjectSumIntensity/sumIntensityCell,   # Fixed
           meanIntensityWramp = meanIntensityWramp/meanIntensityCell,
           medianIntensityWramp = medianIntensityWramp/medianIntensityCell,
           meanIntensityBrightObj = meanIntensityBrightObj/meanIntensityCell,
           sumIntensityBrightObj = sumIntensityBrightObj/sumIntensityCell,
           sumIntensityWramp = sumIntensityWramp/sumIntensityCell,
           sumIntensityNotWramp = sumIntensityNotWramp/sumIntensityCell, 
           sumIntensityNotBright = sumIntensityNotBright/sumIntensityCell, 
           sumIntensitySecond = sumIntensitySecond/sumIntensityCell,
           meanIntensityNotWramp = meanIntensityNotWramp/meanIntensityCell,
           medianIntensityNotWramp = medianIntensityNotWramp/medianIntensityCell,
           meanIntensityNotBright = meanIntensityNotBright/meanIntensityCell,
           medianIntensityNotBright = medianIntensityNotBright/medianIntensityCell,
           meanIntensitySecond = meanIntensitySecond/meanIntensityCell,
           medianIntensitySecond = medianIntensitySecond/medianIntensityCell) %>%
    dplyr::mutate(Intensity_LowerQuartileIntensity = Intensity_LowerQuartileIntensity/meanIntensityCell, 
                  Intensity_MADIntensity = Intensity_MADIntensity/meanIntensityCell,
                  Intensity_MaxIntensityEdge = Intensity_MaxIntensityEdge/meanIntensityCell,
                  Intensity_MaxIntensity = Intensity_MaxIntensity/meanIntensityCell,
                  Intensity_MeanIntensityEdge = Intensity_MeanIntensityEdge/meanIntensityCell,
                  Intensity_MinIntensityEdge = Intensity_MinIntensityEdge/meanIntensityCell,
                  Intensity_MinIntensity = Intensity_MinIntensity/meanIntensityCell,
                  Intensity_UpperQuartileIntensity = Intensity_UpperQuartileIntensity/meanIntensityCell) %>%
    dplyr::select(-meanIntensityCell, -medianIntensityCell, -sumIntensityCell, -Intensity_StdIntensityEdge, -Intensity_StdIntensity, 
           -contains("MeanFrac_")) %>%
    rename_with(~str_c(., paste("_", chName, sep = "")), .cols = -contains(annotFeatures))
  
  normMetrics <- cbind(normNonArea, scaleArea)
}


# Confusion matrix of ML classification (prediction) vs. manual scoring (reference)
# Supply fit from caret to function
analyzeResults <- function(dataset, fit, score, conditionName){
  dataset <- dplyr::select(dataset, -Normalization) %>%
    rename(refScore = score,
           useCondition = conditionName)
  Prediction <- predict(fit, dataset)
  Reference <- dataset$refScore
  Condition <- dataset$useCondition
  Confidence <- dplyr::select(dataset, contains("Confidence"))
  if(length(unique(dataset$refScore)) == 2){
    confusData <- data.frame(Prediction, Reference, Condition, Confidence) %>%
      dplyr::mutate(Prediction = factor(predict(fit, dataset), levels = c("OneEnd", "None")),
             Reference = factor(dataset$ManualScoreMcam, levels = c("OneEnd", "None")))
  }else{
    confusData <- data.frame(as.character(Prediction), as.character(Reference), Condition, Confidence) %>%
      dplyr::mutate(Prediction = factor(Prediction, levels = c("OneEnd", "BothEnds", "None")),
             Reference = factor(Reference, levels = c("OneEnd", "BothEnds", "None")))
  }
  
  conditions <- unique(confusData$Condition)
  for(val in 1:length(conditions)){
    print(conditions[val])
    print(caret::confusionMatrix(confusData$Prediction[confusData$Condition == conditions[val]],
                      confusData$Reference[confusData$Condition == conditions[val]]))
    print("High Confidence")
    print(caret::confusionMatrix(confusData$Prediction[confusData$Condition == conditions[val] & confusData$Confidence !=2],
                      confusData$Reference[confusData$Condition == conditions[val] & confusData$Confidence != 2]))
  }
  
  ggplot(confusData, aes(x = Condition)) + geom_bar(aes(fill = Prediction), position = position_fill(reverse = T))
}

# Alternate function for generating confusion matrix. Add ML classification as a variable to the dataset before inputting to function. Provide names of both variables to compare (e.g., ML classification and manual score)
analyzeResults2 <- function(dataset, className, score, conditionName){
  dataset <- dplyr::select(dataset, -Normalization) %>%
    dplyr::rename(Prediction = className,
                  refScore = score,
                  useCondition = conditionName)
  Prediction <- dataset$Prediction
  Reference <- dataset$refScore
  Condition <- dataset$useCondition
  Confidence <- dplyr::select(dataset, contains("Confidence"))
  if(length(unique(dataset$ManualScoreMcam)) == 2){
    confusData <- data.frame(Prediction, Reference, Condition, Confidence) %>%
      dplyr::mutate(Prediction = factor(predict(fit, dataset), levels = c("OneEnd", "None")),
             Reference = factor(dataset$ManualScoreMcam, levels = c("OneEnd", "None")))
  }else{
    confusData <- data.frame(as.character(Prediction), as.character(Reference), Condition, Confidence) %>%
      dplyr::mutate(Prediction = factor(Prediction, levels = c("OneEnd", "BothEnds", "None")),
             Reference = factor(Reference, levels = c("OneEnd", "BothEnds", "None")))
  }
  
  conditions <- unique(confusData$Condition)
  for(val in 1:length(conditions)){
    print(conditions[val])
    print(caret::confusionMatrix(confusData$Prediction[confusData$Condition == conditions[val]],
                      confusData$Reference[confusData$Condition == conditions[val]]))
    print("High Confidence")
    print(caret::confusionMatrix(confusData$Prediction[confusData$Condition == conditions[val] & confusData$Confidence !=2],
                      confusData$Reference[confusData$Condition == conditions[val] & confusData$Confidence != 2]))
  }
  
  ggplot(confusData, aes(x = Condition)) + geom_bar(aes(fill = Prediction), position = position_fill(reverse = T))
}

# Function for iterative training by upsampling "hard-to-classify" cells into subsequent training sets
upSample <- function(labeledData, classVariableName, startTrainObjects, trainControl, trainFeatures, timesUpsampled){
  labeledData <- labeledData %>%
    rename(class = classVariableName)
  
  gridGbm <- expand.grid(n.trees = c(50, 100, 150, 300, 600),
                            interaction.depth = c(1, 2),
                            shrinkage = c(0.025, 0.1),
                            n.minobsinnode = 10)
  
  gridExtraTrees <- expand.grid(mtry = c(10, 25, 40),
                                numRandomCuts = 3)
  
  trainObjects <- list(Zero = startTrainObjects)
  trainNum <- c("Zero", "One", "Two")
  
  timesUpsampled <- timesUpsampled + 1
  
  for(val in 1:timesUpsampled){
    set.seed(123)
    fitGbm <- caret::train(labeledData %>% filter(Object %in% trainObjects[[trainNum[val]]]) %>%
                             dplyr::select(all_of(trainFeatures)),
                            labeledData$class[labeledData$Object %in% trainObjects[[trainNum[val]]]],
                            method = "gbm",
                            preProcess = NULL,
                            tuneGrid = gridGbm)
    
    set.seed(123)
    fitExtraTrees <- caret::train(labeledData %>% filter(Object %in% trainObjects[[trainNum[val]]]) %>%
                                    dplyr::select(all_of(trainFeatures)),
                                  labeledData$class[labeledData$Object %in% trainObjects[[trainNum[val]]]],
                                  method = "extraTrees",
                                  preProcess = NULL,
                                  tuneGrid = gridExtraTrees)
    
    labeledData$predictGbm <- predict(fitGbm, labeledData %>% dplyr::select(all_of(trainFeatures)))
    labeledData$predictExtra <- predict(fitExtraTrees, labeledData %>% dplyr::select(all_of(trainFeatures)))
    
    falses <- labeledData %>%
      filter(predictGbm != class | predictExtra != class) %>% 
      filter(!Object %in% trainObjects[[trainNum[val]]]) %>% 
      dplyr::select(Object)
    
    set.seed(123)
    newTrainObjects <- c(sample(trainObjects[[trainNum[val]]], 
                                round(.7*length(trainObjects[[trainNum[val]]])), replace = FALSE),
                         sample(falses$Object, round(0.7*nrow(falses)), replace = T))
    
    if(val == 1){
      trainObjects <- list(Zero = trainObjects[[trainNum[val]]], One = newTrainObjects)
    }else if(val == 2){
    trainObjects <-  append(trainObjects, list(Two = newTrainObjects))
    }
    
    if(val == 1){
      models <- list(gbmZero = fitGbm, 
                     extraTreesZero = fitExtraTrees)
    }else if(val == 2){
      models <- append(models, 
                            list(gbmOne = fitGbm, 
                            extraTreesOne = fitExtraTrees))
    }else{
      models <- append(models, 
                            list(gbmTwo = fitGbm, 
                            extraTreesTwo = fitExtraTrees))
    }
  }
  list(trainingSets = trainObjects, fittedModels = models)
}

# Function for iterative training by upsampling "hard-to-classify" cells into subsequent training sets
# Updated version - takes 85% of previous training set for new training set instead of 70%
upSample85 <- function(labeledData, classVariableName, startTrainObjects, trainControl, trainFeatures, timesUpsampled){
  labeledData <- labeledData %>%
    rename(class = classVariableName)
  
  gridGbm <- expand.grid(n.trees = c(50, 100, 150, 300, 600),
                            interaction.depth = c(1, 2),
                            shrinkage = c(0.025, 0.1),
                            n.minobsinnode = 10)
  
  gridExtraTrees <- expand.grid(mtry = c(10, 25, 40),
                                numRandomCuts = 3)
  
  trainObjects <- list(Zero = startTrainObjects)
  trainNum <- c("Zero", "One", "Two")
  
  timesUpsampled <- timesUpsampled + 1
  
  for(val in 1:timesUpsampled){
    set.seed(123)
    fitGbm <- caret::train(labeledData %>% filter(Object %in% trainObjects[[trainNum[val]]]) %>%
                             dplyr::select(all_of(trainFeatures)),
                            labeledData$class[labeledData$Object %in% trainObjects[[trainNum[val]]]],
                            method = "gbm",
                            preProcess = NULL,
                            tuneGrid = gridGbm)
    
    set.seed(123)
    fitExtraTrees <- caret::train(labeledData %>% filter(Object %in% trainObjects[[trainNum[val]]]) %>%
                                    dplyr::select(all_of(trainFeatures)),
                                  labeledData$class[labeledData$Object %in% trainObjects[[trainNum[val]]]],
                                  method = "extraTrees",
                                  preProcess = NULL,
                                  tuneGrid = gridExtraTrees)
    
    labeledData$predictGbm <- predict(fitGbm, labeledData %>% dplyr::select(all_of(trainFeatures)))
    labeledData$predictExtra <- predict(fitExtraTrees, labeledData %>% dplyr::select(all_of(trainFeatures)))
    
    falses <- labeledData %>%
      filter(predictGbm != class | predictExtra != class) %>% 
      filter(!Object %in% trainObjects[[trainNum[val]]]) %>% 
      dplyr::select(Object)
    
    set.seed(123)
    newTrainObjects <- c(sample(trainObjects[[trainNum[val]]], 
                                round(.85*length(trainObjects[[trainNum[val]]])), replace = FALSE),
                         sample(falses$Object, round(0.7*nrow(falses)), replace = T))
    
    if(val == 1){
      trainObjects <- list(Zero = trainObjects[[trainNum[val]]], One = newTrainObjects)
    }else if(val == 2){
    trainObjects <-  append(trainObjects, list(Two = newTrainObjects))
    }
    
    if(val == 1){
      models <- list(gbmZero = fitGbm, 
                     extraTreesZero = fitExtraTrees)
    }else if(val == 2){
      models <- append(models, 
                            list(gbmOne = fitGbm, 
                            extraTreesOne = fitExtraTrees))
    }else{
      models <- append(models, 
                            list(gbmTwo = fitGbm, 
                            extraTreesTwo = fitExtraTrees))
    }
  }
  list(trainingSets = trainObjects, fittedModels = models)
}

# Wrapper function to fit two models and generate a combined classification where both classifiers must agree on one-ended WRAMP structures (reduces false positives at the cost of sensitivity). Classes are added to the metricsClean dataframe.
classifyCleanMetricsCombinedModels <- function(metricsCleaned, metricsScaled, fit1, fit2, columnName){
  metricsCleaned <- arrange(metricsCleaned, Object)
  metricsScaled <- arrange(metricsScaled, Object)
  metricsCleaned$prediction1 <- predict(fit1, metricsScaled)
  metricsCleaned$prediction2 <- predict(fit2, metricsScaled)
  metricsCleaned <- metricsCleaned %>%
    dplyr::mutate(prediction1 = as.character(prediction1), prediction2 = as.character(prediction2)) %>%
    dplyr::mutate(combo = ifelse((prediction1 == "OneEnd" & prediction2 != "OneEnd"), "None", prediction1)) %>%
    dplyr::mutate_at(c("prediction1", "prediction2", "combo"), function(x){factor(x, levels = c("OneEnd", "BothEnds", "None"))}) %>%
    dplyr::select(-prediction1, -prediction2) %>%
    dplyr::rename_with(~ gsub("combo", columnName, .x), .cols = "combo")
}

# Wrapper to apply a single classifer to the data
classifyCleanMetricsOneModel <- function(metricsCleaned, metricsScaled, fit1, fit2, columnName){
  metricsCleaned <- arrange(metricsCleaned, Object)
  metricsScaled <- arrange(metricsScaled, Object)
  metricsCleaned$prediction1 <- predict(fit1, metricsScaled)
  metricsCleaned <- metricsCleaned %>%
  dplyr::rename_with(~ gsub("prediction1", columnName, .x), .cols = "prediction1")
}
```

Annotation files
```{r}
experimentGroup <- data.frame(experimentGroup = c("20210210KD", "20210406KD", "20210513KD", "202107KD", "202107KD", "202107KD", "202107KD", "20211205KD", "20211205KD", "20211205KD", "20211205KD", "20220509KD", "20220530KD"),
                              Experiment = c("20210210_EzrinKD", "20210406_KD", "20210513_MoesinKD", "20210723_KD1", "20210726_KD1", "20210728_KD2", "20210805_KD3", "20211205_KD_EZR_RepN", "20211205_KD_MSN_RepN", "20211205_KD_RDX_StainMyoIIB_RepN", "20211205_KD_RhoA_RepN", "20220509KD", "20220530_KD_RDX"))

annotation0513 <- read.csv("/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/20210513Transfection/Annotation20210513KD.csv") %>%
  dplyr::mutate(mainCondition = str_remove(Condition, "_Stain.*")) %>%
  dplyr::mutate(mainCondition = str_remove(mainCondition, ".*_")) %>%
  dplyr::mutate(mainRep = str_remove(Replicate, "_Stain.*")) %>%
  merge(experimentGroup, by = "Experiment")

annotationOld <- read.csv("/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/OlderExperiments/OlderKnockdowns_Annotation.csv") %>%
  dplyr::mutate(mainCondition = str_remove(Condition, "_Stain.*")) %>%
  dplyr::mutate(mainCondition = str_remove(mainCondition, ".*_")) %>%
  dplyr::mutate(mainRep = str_remove(Replicate, "_Stain.*")) %>%
  merge(experimentGroup, by = "Experiment")

annotation1205 <- read.csv("/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/20211205Transfection/20211205KD_Annotation.csv") %>%
  dplyr::mutate(mainCondition = str_remove(Condition, "_Stain.*")) %>%
  dplyr::mutate(mainCondition = str_remove(mainCondition, ".*_")) %>%
  dplyr::mutate(mainRep = str_remove(Replicate, "_Stain.*")) %>%
  merge(experimentGroup, by = "Experiment")


annotation0509 <- read.csv("/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/20220509Transfection/20220509KD_Annotation.csv") %>%
  dplyr::mutate(mainCondition = str_remove(Condition, "_Stain.*")) %>%
  dplyr::mutate(mainCondition = str_remove(mainCondition, ".*_")) %>%
  dplyr::mutate(mainRep = str_remove(Replicate, "_Stain.*")) %>%
  merge(experimentGroup, by = "Experiment")

annotation0530 <- read_csv("/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/20220530Transfection/Annotation_20220530KD.csv") %>%
  dplyr::mutate(mainCondition = str_remove(Condition, "_Stain.*")) %>%
  dplyr::mutate(mainCondition = str_remove(mainCondition, ".*_")) %>%
  dplyr::mutate(mainRep = str_remove(Replicate, "_Stain.*")) %>%
  merge(experimentGroup, by = "Experiment")

annotation <- rbind(annotation0513 %>% select(all_of(colnames(annotation1205))),
                    annotationOld %>% select(all_of(colnames(annotation1205))),
                    annotation1205, 
                    annotation0509 %>% select(all_of(colnames(annotation1205))),
                    annotation0530 %>% select(all_of(colnames(annotation1205)))) 
  

excludeImages <- c("KD_EZR_MCAM_Myosin_Cov2_001.nd2", "KD_RhoA_Actin_Myosin_cov1_002.nd2", "KD_RDX_Myosin_cov1_003.nd2", "Cntr_EZR_MCAM_Actin_Cov2_007.nd2", "Cntr_RhoA_Actin_ROCK1_2_cov1_006")

# write.csv(annotation, "/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/AllReplicatesAnalysisInR/AllReplicates_RevisedAnalysis_20221101/Output/allAnnotation20221101.csv", row.names = F)

## Check combined annotation file for errors
unique(select(annotation, experimentGroup, Experiment, mainRep))
unique(select(annotation, mainRep, mainCondition, Condition, Replicate))
# I accidentally put the date in the Condition for 20220509KD. However, it did not mess up the mainCondition. It shouldn't affect the results of this script because Condition was used to filter using str_detect().

annotation <- read.csv("/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/AllReplicatesAnalysisInR/AllReplicates_RevisedAnalysis_20221101/Output/allAnnotation20221101.csv")
```

Cell Profiler files:
```{r}
# Two-channel images
cp0513 <- readCp("/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/20210513Transfection/CellProfiler/Output/20220404_CellProfiler_NoNegVals_Image.csv", "/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/20210513Transfection/CellProfiler/Output/20220404_CellProfiler_NoNegVals_Cell.csv")

cpOldPt1 <- readCp("/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/OlderExperiments/CellProfiler/Output/20220507_CellProfiler_NoNegVal_MCAM_Pt1Image.csv", "/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/OlderExperiments/CellProfiler/Output/20220507_CellProfiler_NoNegVal_MCAM_Pt1Cell.csv")

# Three-channel images
cpOldPt2 <- readCp("/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/OlderExperiments/CellProfiler/Output/20220507_CellProfiler_NoNegVal_MCAM_Pt2Image.csv", "/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/OlderExperiments/CellProfiler/Output/20220507_CellProfiler_NoNegVal_MCAM_Pt2Cell.csv")

cp1205 <- readCp("/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/20211205Transfection/CellProfiler/Output/20220210_CellProfiler_NoNegVals_Image.csv", "/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/20211205Transfection/CellProfiler/Output/20220210_CellProfiler_NoNegVals_Cell.csv") %>%
  rename_with(~gsub("Mcam", 'Main', .x), .cols = everything())  %>%
  rename_with(~gsub("Factin", 'Third', .x), .cols = everything())

cp0509 <- readCp("/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/20220509Transfection/CellProfiler/Output/20220523_CellProfiler_NoNegVal_20220509TfnImage.csv", "/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/20220509Transfection/CellProfiler/Output/20220523_CellProfiler_NoNegVal_20220509TfnCell.csv")

cp0530 <- readCp("/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/20220530Transfection/CellProfiler/Output/20220612_CellProfiler_NoNegVal_20220530TfnImage.csv", "/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/20220530Transfection/CellProfiler/Output/20220612_CellProfiler_NoNegVal_20220530TfnCell.csv")

# Check column names match after renaming according to updated format (setdiff should be empty)
setdiff(colnames(cp1205), colnames(cpOldPt2))

cp2channel <- rbind(cp0513, cpOldPt1)
cp3channel <- rbind(cpOldPt2, cp1205, cp0509, cp0530)
```

Matlab files:
```{r}
matlab0513 <- importMatlabMulti("/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/20210513Transfection/MatlabAnalysis/WrampMetrics/Output/80thPctlNoCloseStats_Cell_20220404.csv", "/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/20210513Transfection/MatlabAnalysis/WrampMetrics/Output/80thPctlNoCloseStats_MCAM_20220404.csv", "/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/20210513Transfection/MatlabAnalysis/WrampMetrics/Output/80thPctlNoCloseStats_Other_20220404.csv", "empty", annotation0513, "MCAM", "Other", "empty")

matlabOld <- importMatlabMulti("/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/OlderExperiments/MatlabAnalysis/WrampMetrics/Output/80thPctlNoCloseStats_Cell_20220506.csv", "/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/OlderExperiments/MatlabAnalysis/WrampMetrics/Output/80thPctlNoCloseStats_MCAM_20220506.csv", "/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/OlderExperiments/MatlabAnalysis/WrampMetrics/Output/80thPctlNoCloseStats_Other_20220506.csv", "/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/OlderExperiments/MatlabAnalysis/WrampMetrics/Output/80thPctlNoCloseStats_Factin_20220506.csv", annotationOld, "MCAM", "Other", "Third")
# Image 22_Cov1_001 was duplicated in Matlab analysis, but duplicate rows are removed during import

matlab1205 <- importMatlabMulti("/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/20211205Transfection/MatlabAnalysis/WrampMetrics/Output/80thPctlNoCloseStats_Cell_20220410.csv", "/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/20211205Transfection/MatlabAnalysis/WrampMetrics/Output/80thPctlNoCloseStats_MCAM_20220410.csv", "/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/20211205Transfection/MatlabAnalysis/WrampMetrics/Output/80thPctlNoCloseStats_Other_20220410.csv",
                                "/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/20211205Transfection/MatlabAnalysis/WrampMetrics/Output/80thPctlNoCloseStats_Factin_20220410.csv", annotation1205, "MCAM", "Other", "Third") 
#Note some images not in annotation file, but conveniently from RDX knockdown

matlab0509Pt1 <- importMatlabMulti("/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/20220509Transfection/MatlabAnalysis/WrampMetrics/Output/80thPctlNoCloseStats_Cell_20220521.csv", "/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/20220509Transfection/MatlabAnalysis/WrampMetrics/Output/80thPctlNoCloseStats_MCAM_20220521.csv", "/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/20220509Transfection/MatlabAnalysis/WrampMetrics/Output/80thPctlNoCloseStats_Other_20220521.csv",
                                "/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/20220509Transfection/MatlabAnalysis/WrampMetrics/Output/80thPctlNoCloseStats_Factin_20220521.csv", annotation0509, "MCAM", "Other", "Third")

matlab0509Pt2 <- importMatlabMulti("/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/20220509Transfection/MatlabAnalysis/WrampMetrics/Output/80thPctlNoCloseStats_Cell_20220522.csv", "/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/20220509Transfection/MatlabAnalysis/WrampMetrics/Output/80thPctlNoCloseStats_MCAM_20220522.csv", "/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/20220509Transfection/MatlabAnalysis/WrampMetrics/Output/80thPctlNoCloseStats_Other_20220522.csv",
                                "/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/20220509Transfection/MatlabAnalysis/WrampMetrics/Output/80thPctlNoCloseStats_Factin_20220522.csv", annotation0509, "MCAM", "Other", "Third")

matlab0509 <- rbind(matlab0509Pt1, matlab0509Pt2)
remove(matlab0509Pt1)
remove(matlab0509Pt2)

matlab0530 <- importMatlabMulti("/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/20220530Transfection/MatlabAnalysis/WrampMetrics/Output/80thPctlNoCloseStats_Cell_20220611.csv", "/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/20220530Transfection/MatlabAnalysis/WrampMetrics/Output/80thPctlNoCloseStats_MCAM_20220611.csv", "/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/20220530Transfection/MatlabAnalysis/WrampMetrics/Output/80thPctlNoCloseStats_Other_20220611.csv",
                                "/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/20220530Transfection/MatlabAnalysis/WrampMetrics/Output/80thPctlNoCloseStats_Factin_20220611.csv", annotation0530, "MCAM", "Other", "Third")

matlab2channel <- rbind(matlab0513 %>%
  dplyr::select(-TxRed), 
                        matlabOld %>% 
                          filter(Object %in% cpOldPt1$Object) %>% 
                          dplyr::select(all_of(colnames(matlab0513 %>% dplyr::select(-TxRed))))) %>%
  dplyr::select(-all_of(c("DAPI", "FITC")))

matlab3channel <- rbind(matlabOld %>% 
                          filter(Object %in% cpOldPt2$Object) %>% 
                          dplyr::select(-all_of(c("DAPI", "FITC", "TxRedCy5"))), 
                        matlab1205,
                        matlab0509 %>%
                          dplyr::select(-all_of(c("DAPI", "FITC", "TxRedCy5"))),
                        matlab0530 %>%
                          dplyr::select(-all_of(c("DAPI", "FITC", "TxRedCy5"))))

# Check that object names match in Matlab and CellProfiler dataframes (setdiff should be empty)
setdiff(matlab2channel$Object, cp2channel$Object)
setdiff(matlab3channel$Object, cp3channel$Object) # Note: cp files are usually several rows longer because Matlab skips segmented objects that fail the function (usually very weirdly shaped mask from debris or rounded cell that the function can't accomodate)
```
Combine and clean features
```{r}
metricsClean2Channel <- combineMetrics(matlab2channel, cp2channel, "_BgSubtractedMain", "_BgSubtractedOther", "empty", "MCAM", "Other", "empty")

metricsClean3Channel  <- combineMetrics(matlab3channel, cp3channel, "_BgSubtractedMain", "_BgSubtractedOther", "_BgSubtractedThird", "MCAM", "Other", "Third")

# Combine MCAM (SC-18837) and "Other" channel data from two- and three-channel experiments
metricsCleanMcamOtherAllMcam488 <- rbind(metricsClean2Channel,
                               metricsClean3Channel %>% dplyr::select(-all_of(setdiff(colnames(metricsClean3Channel), colnames(metricsClean2Channel))))) %>%
    filter(Exclude != "Omit" | is.na(Exclude), 
           !str_detect(Replicate, "StainCD44"), 
           !str_detect(Replicate, "StainMCAMC"),
           !str_detect(Image, "RDX488")) %>% # Stained using rabbit MCAM antibody or no MCAM
    filter(str_detect(Condition, "StainMCAM-")) # Redundancy

# Remove experiments/conditions not included in classifier training
metricsCleanMcamOther <- metricsCleanMcamOtherAllMcam488 %>%
  filter(!experimentGroup %in% c("20210513KD", "202107KD")) %>%
  filter(mainRep != "20211205_siRhoA") %>% 
  filter(!str_detect(Experiment, "20211205_KD_RDX")) # Slides may have been mislabeled

unique(metricsCleanMcamOther$Replicate)
```

Scale and normalize features (originally from Development of ML in Chapter 3):
```{r}
normAreaFeatures <- read.csv("/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/AllReplicatesAnalysisInR/AllReplicates_RevisedAnalysis_20221101/InputForML/ScalingValues/normAreaFeatures.csv")[,"x"]

normAreaFeatures.MCAM <- normAreaFeaturesChannel(normAreaFeatures, "MCAM")

medianAreas.MCAM <- read.csv("/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/AllReplicatesAnalysisInR/AllReplicates_RevisedAnalysis_20221101/InputForML/ScalingValues/medianAreasMcam.csv")

colocFeatures <- read.csv("/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/AllReplicatesAnalysisInR/AllReplicates_RevisedAnalysis_20221101/InputForML/ScalingValues/colocalizationFeatures.csv")[,"x"]

metricsScaled.MCAM <- scaleAreaIntensity(metricsCleanMcamOther, 
                                         normAreaFeatures.MCAM, medianAreas.MCAM, colocFeatures, "MCAM", "_BgSubtractedMain")
```

Compiled manual scoring not from copolarization analysis (See separate script):
```{r}
manualScoringTemp <- read.csv("/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/AllReplicatesAnalysisInR/AllReplicates_RevisedAnalysis_20221101/InputForML/manualScoringNoCopolar_20221104_New.csv")

manualScoring <- manualScoringTemp %>%
  filter(Exclude != "Omit" | is.na(Exclude), 
           !str_detect(Replicate, "StainCD44"), 
           !str_detect(Replicate, "StainMCAMC"),
           !str_detect(Image, "RDX488")) %>% # Stained using rabbit MCAM antibody or no MCAM
  filter(str_detect(Condition, "StainMCAM-")) %>%
  filter(!experimentGroup %in% c("20210513KD", "202107KD")) %>%
  filter(mainRep != "20211205_siRhoA") %>% 
  filter(!str_detect(Experiment, "20211205_KD_RDX"))

manualScoring %>% group_by(experimentGroup, ManualScoreMcam) %>% count() %>% ungroup()

```

ML: upSampling with keeping either 70% (original function) or 85% of the previous training set when sampling in n = .7 of misclassified cells
```{r}
trainingObjectsMcamTemp <- rbind(manualScoring %>%
      filter(Exclude != "Omit" | is.na(Exclude),
           !str_detect(Replicate, "StainCD44"),
           !str_detect(Replicate, "StainMCAMC"),
           !str_detect(Image, "RDX488")) %>% # Stained using rabbit MCAM antibody or no MCAM
      filter(str_detect(Condition, "StainMCAM-")) %>%
      filter(!experimentGroup %in% c("20210513KD", "202107KD")) %>%
      filter(mainRep != "20211205_siRhoA") %>%
      filter(!str_detect(Experiment, "20211205_KD_RDX")) %>%
      filter(is.na(Segmentation), is.na(WrongObject)) %>% # Remove cells with bad segmentation/brightest object from set used for ML
      filter(ManualScoreMcam == "BothEnds") %>%
        filter(!str_detect(Image, "RDX488")) %>%
      group_by(experimentGroup, ManualScoreMcam) %>%
      slice_sample(n = 15, replace = F) %>%
        ungroup(),
    manualScoring %>%
      filter(Exclude != "Omit" | is.na(Exclude),
           !str_detect(Replicate, "StainCD44"),
           !str_detect(Replicate, "StainMCAMC"),
           !str_detect(Image, "RDX488")) %>% # Stained using rabbit MCAM antibody or no MCAM
      filter(str_detect(Condition, "StainMCAM-")) %>%
      filter(!experimentGroup %in% c("20210513KD", "202107KD")) %>%
      filter(mainRep != "20211205_siRhoA") %>%
      filter(!str_detect(Experiment, "20211205_KD_RDX")) %>%
      filter(is.na(Segmentation), is.na(WrongObject)) %>%
      filter(ManualScoreMcam == "OneEnd") %>%
      filter(!str_detect(Image, "RDX488")) %>%
      group_by(experimentGroup, ManualScoreMcam) %>%
      slice_sample(n = 150, replace = F) %>%
      ungroup(),
    manualScoring %>%
      filter(Exclude != "Omit" | is.na(Exclude),
           !str_detect(Replicate, "StainCD44"),
           !str_detect(Replicate, "StainMCAMC"),
           !str_detect(Image, "RDX488")) %>% # Stained using rabbit MCAM antibody or no MCAM
      filter(str_detect(Condition, "StainMCAM-")) %>%
      filter(!experimentGroup %in% c("20210513KD", "202107KD")) %>%
      filter(mainRep != "20211205_siRhoA") %>%
      filter(!str_detect(Experiment, "20211205_KD_RDX")) %>%
      filter(is.na(Segmentation), is.na(WrongObject)) %>%
      filter(ManualScoreMcam == "None") %>%
      filter(!str_detect(Image, "RDX488")) %>%
      group_by(experimentGroup, ManualScoreMcam) %>%
      slice_sample(n = 200, replace = F) %>%
      ungroup()) %>%
  dplyr::select(Object, ManualScoreMcam)

sum(duplicated(trainingObjectsMcamTemp$Object))
trainingObjectsMcamTemp %>% group_by(ManualScoreMcam) %>% count() %>% ungroup()
set.seed(123)
trainingSetMcamObjects <- trainingObjectsMcamTemp[createDataPartition(trainingObjectsMcamTemp$ManualScoreMcam, p = 0.65, list = F, times = 1), "Object"]

metricsScaled.MCAM.labeled <- metricsScaled.MCAM %>%
  merge(trainingObjectsMcamTemp %>% dplyr::select(ManualScoreMcam, Object), by = "Object") %>%
  merge(manualScoring %>% dplyr::select(Object, ConfidenceMcam), by = "Object")

initialMcamModel <- readRDS("/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/AllReplicatesAnalysisInR/AnalysisForThesisDraft-ContainsError/Output/ClassifiersForMcam/modelList20220531") # Used to get list of features

reducedFeatures.MCAM <- colnames(initialMcamModel[["fittedModels"]][["extraTreesTwo"]][["trainingData"]] %>% dplyr::select(-.outcome))
reducedFeatures.MCAM2 <- colnames(initialMcamModel[["fittedModels"]][["extraTreesTwo"]][["trainingData"]] %>% dplyr::select(-.outcome, -contains("Texture"), -contains("CV_IntensityEdge_MCAM")))

myControlUpsample <- trainControl(method = "repeatedcv",
                                  number = 10, # number of k-folds
                                  repeats = 3,
                                  savePredictions = "final",
                                  classProbs = T)

mcamKDmodel1 <- upSample(metricsScaled.MCAM.labeled, "ManualScoreMcam", trainingSetMcamObjects$Object, myControlUpsample, reducedFeatures.MCAM, timesUpsampled = 2)
# # extraTrees model must be "prepared" for saving or it will not load in the future
# prepareForSave(mcamKDmodel1[["fittedModels"]][["extraTreesZero"]]$finalModel)
# prepareForSave(mcamKDmodel1[["fittedModels"]][["extraTreesOne"]]$finalModel)
# prepareForSave(mcamKDmodel1[["fittedModels"]][["extraTreesTwo"]]$finalModel)
# saveRDS(mcamKDmodel1, "/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/AllReplicatesAnalysisInR/AllReplicates_RevisedAnalysis_20221101/Output/ClassifiersForMcam/modelList20221104")

mcamKDmodel2 <- upSample(metricsScaled.MCAM.labeled, "ManualScoreMcam", trainingSetMcamObjects$Object, myControlUpsample, reducedFeatures.MCAM2, timesUpsampled = 2)
# prepareForSave(mcamKDmodel2[["fittedModels"]][["extraTreesZero"]]$finalModel)
# prepareForSave(mcamKDmodel2[["fittedModels"]][["extraTreesOne"]]$finalModel)
# prepareForSave(mcamKDmodel2[["fittedModels"]][["extraTreesTwo"]]$finalModel)
# saveRDS(mcamKDmodel2, "/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/AllReplicatesAnalysisInR/AllReplicates_RevisedAnalysis_20221101/Output/ClassifiersForMcam/modelList20221104-NoTexture")

mcamKDmodel1_85 <- upSample85(metricsScaled.MCAM.labeled, "ManualScoreMcam", trainingSetMcamObjects$Object, myControlUpsample, reducedFeatures.MCAM, timesUpsampled = 2)
# # extraTrees model must be "prepared" for saving or it will not load in the future
# prepareForSave(mcamKDmodel1_85[["fittedModels"]][["extraTreesZero"]]$finalModel)
# prepareForSave(mcamKDmodel1_85[["fittedModels"]][["extraTreesOne"]]$finalModel)
# prepareForSave(mcamKDmodel1_85[["fittedModels"]][["extraTreesTwo"]]$finalModel)
# saveRDS(mcamKDmodel1_85, "/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/AllReplicatesAnalysisInR/AllReplicates_RevisedAnalysis_20221101/Output/ClassifiersForMcam/modelList20221104_85up")

mcamKDmodel2_85 <- upSample85(metricsScaled.MCAM.labeled, "ManualScoreMcam", trainingSetMcamObjects$Object, myControlUpsample, reducedFeatures.MCAM2, timesUpsampled = 2)
prepareForSave(mcamKDmodel2_85[["fittedModels"]][["extraTreesZero"]]$finalModel)
# prepareForSave(mcamKDmodel2_85[["fittedModels"]][["extraTreesOne"]]$finalModel)
# prepareForSave(mcamKDmodel2_85[["fittedModels"]][["extraTreesTwo"]]$finalModel)
# saveRDS(mcamKDmodel2_85, "/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/AllReplicatesAnalysisInR/AllReplicates_RevisedAnalysis_20221101/Output/ClassifiersForMcam/modelList20221104-NoTexture_85up")
```

Load previously run classifiers:
```{r}
mcamKDmodel1 <- readRDS("/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/AllReplicatesAnalysisInR/AllReplicates_RevisedAnalysis_20221101/Output/ClassifiersForMcam/modelList20221104")
mcamKDmodel2 <- readRDS("/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/AllReplicatesAnalysisInR/AllReplicates_RevisedAnalysis_20221101/Output/ClassifiersForMcam/modelList20221104-NoTexture")
mcamKDmodel1_85 <- readRDS("/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/AllReplicatesAnalysisInR/AllReplicates_RevisedAnalysis_20221101/Output/ClassifiersForMcam/modelList20221104_85up")
mcamKDmodel2_85 <- readRDS("/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/AllReplicatesAnalysisInR/AllReplicates_RevisedAnalysis_20221101/Output/ClassifiersForMcam/modelList20221104-NoTexture_85up")

# Check that only mouse MCAM was trained on
sum(str_detect(c(mcamKDmodel2_85[["trainingSets"]][["Zero"]], mcamKDmodel2_85[["trainingSets"]][["One"]], mcamKDmodel2_85[["trainingSets"]][["Two"]]), "RDX488"))
```

Classify cells - try combining different classifiers to look for the one with the best accuracy.
NOTE: This is the preliminary assessment of accuracy which wass used during optimization of the ML training. It uses cells which included those used during iterative training (excluding the cells for the training set for each respective round). This may bias the results because the test set is not fully independent of iterative training. 

Accuracy for the paper was reported on a separate sample of cells scored later which excluded any cells used in iterative training. This analysis is shown in the Sensitivity-Specificity-Precision-ImportantFeatures.Rmd notebook.
```{r}
# Second upsample gbm and extraTrees classifier
metricsCleanMcamOther.Classified.Two <- classifyCleanMetricsCombinedModels(classifyCleanMetricsCombinedModels(metricsCleanMcamOther, 
                                                               metricsScaled.MCAM, 
                                                                mcamKDmodel2[["fittedModels"]][["gbmTwo"]],
                                                mcamKDmodel2[["fittedModels"]][["extraTreesTwo"]], 
                                                columnName = "comboGbmExtraTwo_MCAM2"),
                                                metricsScaled.MCAM, 
                                                                mcamKDmodel1[["fittedModels"]][["gbmTwo"]],
                                                mcamKDmodel1[["fittedModels"]][["extraTreesTwo"]], 
                                                columnName = "comboGbmExtraTwo_MCAM1")

metricsCleanMcamOther.Classified.Two85 <- classifyCleanMetricsCombinedModels(classifyCleanMetricsCombinedModels(metricsCleanMcamOther, 
                                                               metricsScaled.MCAM, 
                                                                mcamKDmodel2_85[["fittedModels"]][["gbmTwo"]],
                                                mcamKDmodel2_85[["fittedModels"]][["extraTreesTwo"]], 
                                                columnName = "comboGbmExtraTwo_MCAM2"),
                                                metricsScaled.MCAM, 
                                                                mcamKDmodel1_85[["fittedModels"]][["gbmTwo"]],
                                                mcamKDmodel1_85[["fittedModels"]][["extraTreesTwo"]], 
                                                columnName = "comboGbmExtraTwo_MCAM1")

# First upsample gbm and extraTrees
metricsCleanMcamOther.Classified.One85 <- classifyCleanMetricsCombinedModels(classifyCleanMetricsCombinedModels(metricsCleanMcamOther, 
                                                               metricsScaled.MCAM, 
                                                                mcamKDmodel2_85[["fittedModels"]][["gbmOne"]],
                                                mcamKDmodel2_85[["fittedModels"]][["extraTreesOne"]], 
                                                columnName = "comboGbmExtraOne_MCAM2"),
                                                metricsScaled.MCAM, 
                                                                mcamKDmodel1_85[["fittedModels"]][["gbmOne"]],
                                                mcamKDmodel1_85[["fittedModels"]][["extraTreesOne"]], 
                                                columnName = "comboGbmExtraOne_MCAM1")
```

Preliminary comparision of accuracy of classifiers:
```{r}
metricsCleanMcamOther.Classified.Labeled.Two <- merge(metricsCleanMcamOther.Classified.Two, manualScoring %>% dplyr::select(Object, ManualScoreMcam, ConfidenceMcam), by = "Object") 
  
metricsCleanMcamOther.Classified.Labeled.Two85 <- merge(metricsCleanMcamOther.Classified.Two85, manualScoring %>% dplyr::select(Object, ManualScoreMcam, ConfidenceMcam), by = "Object") 
  
metricsCleanMcamOther.Classified.Labeled.One85 <- merge(metricsCleanMcamOther.Classified.One85, manualScoring %>% dplyr::select(Object, ManualScoreMcam, ConfidenceMcam), by = "Object") 

analyzeResults2(metricsCleanMcamOther.Classified.Labeled.Two %>% filter(!Object %in% mcamKDmodel2[["trainingSets"]][["Two"]]), "comboGbmExtraTwo_MCAM2", "ManualScoreMcam", "experimentGroup")

analyzeResults2(metricsCleanMcamOther.Classified.Labeled.Two85 %>% filter(!Object %in% mcamKDmodel2_85[["trainingSets"]][["Two"]]), "comboGbmExtraTwo_MCAM2", "ManualScoreMcam", "experimentGroup")

analyzeResults2(metricsCleanMcamOther.Classified.Labeled.Two %>% filter(!Object %in% mcamKDmodel1[["trainingSets"]][["Two"]]), "comboGbmExtraTwo_MCAM1", "ManualScoreMcam", "experimentGroup") # Low sensitivity

analyzeResults2(metricsCleanMcamOther.Classified.Labeled.Two85 %>% filter(!Object %in% mcamKDmodel1_85[["trainingSets"]][["Two"]]), "comboGbmExtraTwo_MCAM1", "ManualScoreMcam", "experimentGroup") # Low sensitivity

analyzeResults2(metricsCleanMcamOther.Classified.Labeled.One85 %>% filter(!Object %in% mcamKDmodel2_85[["trainingSets"]][["One"]]), "comboGbmExtraOne_MCAM2", "ManualScoreMcam", "experimentGroup")


analyzeResults2(metricsCleanMcamOther.Classified.Labeled.Two %>% filter(!Object %in% mcamKDmodel2[["trainingSets"]][["Two"]]), "comboGbmExtraTwo_MCAM2", "ManualScoreMcam", "mainRep")

analyzeResults2(metricsCleanMcamOther.Classified.Labeled.Two85 %>% filter(!Object %in% mcamKDmodel2_85[["trainingSets"]][["Two"]]), "comboGbmExtraTwo_MCAM2", "ManualScoreMcam", "mainRep")
```
Keeping more of the original training set during upsampling (upSample85) was more accurate (kept training sets from shrinking as much). Interpret cautiously as this is based on preliminary accuracy measurements which are not fully independent of the training sets (see above).

Removing texture (Haralick) features improves sensitivity. 

Final classification uses the models from the last iteration of training:
```{r}
metricsCleanMcamOther.Classified <- classifyCleanMetricsCombinedModels(metricsCleanMcamOther, 
                                                                       metricsScaled.MCAM, 
                                                                       mcamKDmodel2_85[["fittedModels"]][["gbmTwo"]],
                                                                       mcamKDmodel2_85[["fittedModels"]][["extraTreesTwo"]], 
                                                                       columnName = "comboGbmExtraTwo_MCAM2")

all(str_detect(metricsCleanMcamOther.Classified$Condition, "StainMCAM-"))
sum(str_detect(metricsCleanMcamOther.Classified$Condition, "StainRDX"))
```

Finding any cells not included in manual scoring from above, randomly shuffle, and blind for co-polarization scoring:
```{r}
oneEnd <- metricsCleanMcamOther.Classified %>%
  filter(comboGbmExtraTwo_MCAM2 == "OneEnd")

remainingOneEnd <- oneEnd %>%
  filter(!Object %in% manualScoring$Object[manualScoring$ManualScoreMcam == "OneEnd"])

# # Shuffle cells
# nCells <- length(remainingOneEnd$Object)
# set.seed(123)
# fileNameV1 <- paste(gsub(".nd2", "_Img_Cell", remainingOneEnd$Object)[sample(nCells, nCells, replace = F)], "_80thPctlNoClose.png", sep = "")
# fileNameV2 <- gsub("_80thPctlNoClose.png", "_Img_Cell_80thPctlNoClose.png", gsub("_Img_Cell", "", fileNameV1))
# 
# renameMatrix <- data.frame(newNum = 1:nCells, imgNameV1 = fileNameV1, imgNameV2 = fileNameV2) %>%
#   dplyr::mutate(newNameImg = paste("80thPctlNoClose_r", as.character(newNum), "_Img.png", sep = ""),
#          newNameFig = paste("80thPctlNoClose_", as.character(newNum), "_Fig.png", sep = ""),
#          figNameV1 = paste("Bg_", str_replace(imgNameV1, "Img", "Figure"), sep = ""),
#          figNameV2 = str_replace(imgNameV2, "Img", "Figure")) %>%
#    dplyr::mutate(pathNameImgV1 = paste("/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/AllKDFigures/", imgNameV1, sep = ""),
#           pathNameImgV2 = paste("/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/AllKDFigures/", imgNameV2, sep = ""),
#           pathNameFigV1 = paste("/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/AllKDFigures/", figNameV1, sep = ""),
#           pathNameFigV2 = paste("/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/AllKDFigures/", figNameV2, sep = "")) %>%
#   dplyr::mutate(toPathNameImgV1 = paste("/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/CopolarRescoring20221109/", imgNameV1, sep = ""),
#           toPathNameImgV2 = paste("/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/CopolarRescoring20221109/", imgNameV2, sep = ""),
#           toPathNameFigV1 = paste("/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/CopolarRescoring20221109/", figNameV1, sep = ""),
#           toPathNameFigV2 = paste("/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/CopolarRescoring20221109/", figNameV2, sep = ""))
# 
# file.copy(from = renameMatrix$pathNameImgV1, to = renameMatrix$toPathNameImgV1)
# file.copy(from = renameMatrix$pathNameImgV2, to = renameMatrix$toPathNameImgV2)
# file.copy(from = renameMatrix$pathNameFigV1, to = renameMatrix$toPathNameFigV1)
# file.copy(from = renameMatrix$pathNameFigV2, to = renameMatrix$toPathNameFigV2)
# 
# setwd("/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/CopolarRescoring20221109/")
# write.csv(renameMatrix, "Blinding_Rescoring20221109.csv")
# file.rename(renameMatrix$imgNameV1, renameMatrix$newNameImg)
# file.rename(renameMatrix$imgNameV2, renameMatrix$newNameImg)
# file.rename(renameMatrix$figNameV1, renameMatrix$newNameFig)
# file.rename(renameMatrix$figNameV2, renameMatrix$newNameFig)
# 
# renameMatrixFix <- renameMatrix %>% dplyr::select(newNameFig) %>%
#   mutate(newNameFigR = str_replace(newNameFig, "Close_", "Close_r"))
# setwd("/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/CopolarRescoring20221109/")
# file.rename(renameMatrixFix$newNameFig, renameMatrixFix$newNameFigR)
```

Copolarization scoring (Note: I scored all cells without a "OneEnd" manual scoring used for ML instead of using old copolarization analyses)
```{r}
# Manual scoring cleaned and unblinded in "RecompileManualScoring20221103" script
scoringCopolarRescoring <- read.csv("/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/AllReplicatesAnalysisInR/AllReplicates_RevisedAnalysis_20221101/InputForML/ManualRescoringCopolarization20221109.csv") %>% dplyr::select(-X)

copolarizationOneEnd <- rbind(scoringCopolarRescoring,
                              manualScoring %>% filter(!Object %in% scoringCopolarRescoring$Object)) %>%
  filter(Object %in% metricsCleanMcamOther.Classified$Object[metricsCleanMcamOther.Classified$comboGbmExtraTwo_MCAM2 == "OneEnd"])

# All cells classified as "OneEnd" have copolarization score
setdiff(oneEnd$Object, copolarizationOneEnd$Object)
nrow(oneEnd) == nrow(copolarizationOneEnd)

copolarizationOneEnd %>% group_by(Segmentation, ManualScoreMcam) %>% count() %>% ungroup() # About 11% of classified cells had bad segmentation/focus or were a true "None"
copolarizationOneEnd %>% group_by(Segmentation, WrongObject, ManualScoreMcam) %>% count() %>% ungroup()

# write.csv(copolarizationOneEnd, "/Volumes/ahngrp/Suzannah_Thesis_Paper/ERM_Knockdown/AllReplicatesAnalysisInR/AllReplicates_RevisedAnalysis_20221101/Output/copolarization_OneEnd_Class_MCAM-488_20221104.csv", row.names = F)
```
